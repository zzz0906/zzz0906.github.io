<!DOCTYPE html>
<html lang="en,zh-CN,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zzz0906.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;],[&#39;\\(&#39;,&#39;\\)&#39;]]} });     PrefaceGot two certifications from RL in Alberta, I feel I understand more concepts in RL. Keep going! The third part - I">
<meta property="og:type" content="article">
<meta property="og:title" content="ReinforcementLearning-Principle-Day12">
<meta property="og:url" content="https://zzz0906.github.io/2022/02/03/ReinforcementLearning-Principle-Day12/index.html">
<meta property="og:site_name" content="Zhongzhu&#39;s Blog">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;],[&#39;\\(&#39;,&#39;\\)&#39;]]} });     PrefaceGot two certifications from RL in Alberta, I feel I understand more concepts in RL. Keep going! The third part - I">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-02-03T11:43:01.000Z">
<meta property="article:modified_time" content="2023-08-31T08:44:59.000Z">
<meta property="article:author" content="Zhongzhu &#x2F; Chralie Zhou">
<meta property="article:tag" content="ReinforcementLearning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zzz0906.github.io/2022/02/03/ReinforcementLearning-Principle-Day12/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>ReinforcementLearning-Principle-Day12 | Zhongzhu's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhongzhu's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Keep</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zzz0906.github.io/2022/02/03/ReinforcementLearning-Principle-Day12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhongzhu / Chralie Zhou">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhongzhu's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ReinforcementLearning-Principle-Day12
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-02-03 11:43:01" itemprop="dateCreated datePublished" datetime="2022-02-03T11:43:01+00:00">2022-02-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-08-31 08:44:59" itemprop="dateModified" datetime="2023-08-31T08:44:59+00:00">2023-08-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'],['\\(','\\)']]} }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>Got two certifications from RL in Alberta, I feel I understand more concepts in RL. Keep going! The third part - I see it’s related to the GD &amp; function approximation.</p>
<ul>
<li>Introduction</li>
<li>Value-function Approximation</li>
<li>The Prediction Objective (VE)</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Control Problem is the task of improving a policy. So, if we only need to evaluate the state, it’s not a control problem.</p>
<p>Can we represent the value function with a tabel? =&gt; no; GD / Average award.</p>
<p>The novelty in this chapter is that the approximate value function is represented not as a table but as a parameterized functional form with weight vector w $\in R^d$ .</p>
<p>In fact, all the theoretical results for methods using function approximation presented in this part of the book apply equally well to cases of partial observability.</p>
<h2 id="9-1-Value-function-Approximation"><a href="#9-1-Value-function-Approximation" class="headerlink" title="9.1 Value-function Approximation"></a>9.1 Value-function Approximation</h2><p>For the table update, Now we permit arbitrarily complex and sophisticated methods to implement the update. </p>
<p>** Supervisde learning we will have true lable. But TD-method, we don’t have the true label, we onyl have the next state’s expected value which will be changed **</p>
<h2 id="9-2-The-Prediction-Objective-VE"><a href="#9-2-The-Prediction-Objective-VE" class="headerlink" title="9.2 The Prediction Objective (VE)"></a>9.2 The Prediction Objective (VE)</h2><p>By assumption we have far more states than weights, so making one state’s estimate more accurate invariably means making others’ less accurate. We are obligated then to say which states we care most about. We must specify a state distribution $u(s)~0, \sumμ(s) = 1$, representing how much we care about the error in each state s. And the MSAE of general loss function will be updated as $\sum u(s) [v_\pi(s) - \hat{v}(s,w)]$</p>
<p>Often $μ(s)$ is chosen to be the fraction of time spent in s. Under on-policy training this is called the on-policy distribution;</p>
<h2 id="9-3-Stochastic-gradient-and-Semi-gradient-Methods"><a href="#9-3-Stochastic-gradient-and-Semi-gradient-Methods" class="headerlink" title="9.3 Stochastic-gradient and Semi-gradient Methods"></a>9.3 Stochastic-gradient and Semi-gradient Methods</h2><p>Sometimes, the target function may not be the best perfect target, For example, Ut might be a noise-corrupted version of v(St), or it might be one of the bootstrapping targets using vˆ mentioned in the previous section.</p>
<p>Because the true value of a state is the expected value of the return following it, the Monte Carlo target Ut = Gt is by definition an unbiased estimate of vt(St).</p>
<p>Bootstrapping methods are not in fact instances of true gradient descent (Barnard, 1993). They take into account the effect of changing the weight vector wt on the estimate, but ignore its effect on the target. They include only a part of the gradient and, accordingly, we call them semi-gradient methods.</p>
<p>Pay attention that the TD(0) algorithm let us use v(S’,w) + R as the target, thus this target function also have the weights not like the supervised learning.</p>
<p>The value of a state is estimated as its group’s component, and when the state is updated, that component alone is updated. State aggregation is a special case of SGD (9.7) in which the gradient, rvˆ(St,wt), is 1 for St’s group’s component and 0 for the other components.</p>
<p>In my understanding, the different between TD(0) and Monte Carlo is the target function. TD(0) use the next state’s value as the target function, but Monte Carlo use the real return as the target function. Even in the function approximation, the difference is still there. TD(0) contian the bias. Because this bias, when performing gradient descent, our target is the next state’s value that is still calucalted by the value function. So, the target function is not the real value function. That’s reason we call it semi-gradient.</p>
<p>$$\mathbf{w_{t+1}} = \mathbf{w_{t}} + \alpha \delta_t \nabla \hat{v}(S_t,\mathbf{w_{t}})$$</p>
<p>At each time step, we update the weights in the direction  $g_t = \delta_t \nabla \hat{v}(S_t,\mathbf{w_t})$ using a fixed step-size $\alpha$. $\delta_t = R_{t+1} + \gamma \hat{v}(S_{t+1},\mathbf{w_{t}}) - \hat{v}(S_t,\mathbf{w_t})$ is the TD-error. $\nabla \hat{v}(S_t,\mathbf{w_{t}})$ is the gradient of the value function with respect to the weights.</p>
<h2 id="9-4-Linear-Methods"><a href="#9-4-Linear-Methods" class="headerlink" title="9.4 Linear Methods"></a>9.4 Linear Methods</h2><p>When using the semi-gradient method, if I set the value function as v = x. Then the gradient of x is equal to 1. Then we perform gradient decent, the update will be alpha<em>(Gt - x)*x’ = aplha\</em>(Gt-x) that is the tabular fourmula we had before. So, the linear method is a special case of the semi-gradient method.</p>
<p>Linear methods approximate the state-value function by the inner product between w and x(s)</p>
<p>Almost all useful convergence results for learning systems of all kinds are for linear (or simpler) function approximation methods.</p>
<p>A interesting point here is if the system converges, it must converge to the situation that  $b - A*w_t = 0$</p>
<p>$\mathbb{E}[W_{t+1}|W_t] = w_t + \alpha<em>(b-A</em>w_t)$</p>
<p>In general, $w_t$ will be reduced toward zero whenever A is positive definite, meaning $y^\mathbb{T}Ay &gt; 0$ for any real vector y 6= 0.</p>
<p>On the other hand, recall that the TD methods are often of vastly reduced variance compared to Monte Carlo methods, and thus faster, as we saw in Chapters 6 and 7</p>
<p>$\overline{VE}(W_{TD}) &lt;= \frac{1}{1-\gamma}*min_w\overline{VE}(w)$ is the asymptotic error for the TD method. linaer semi-gradient DP with updates according to the on-policy distribution will also converge to the TD fixed point. (TD uses next time’s value included into current time’s update. semi gradient use gradient to update the TD value function.)</p>
<h2 id="9-5-Feature-Construction-for-Linear-Methods"><a href="#9-5-Feature-Construction-for-Linear-Methods" class="headerlink" title="9.5 Feature Construction for Linear Methods"></a>9.5 Feature Construction for Linear Methods</h2><h2 id="9-5-1-Polynomials"><a href="#9-5-1-Polynomials" class="headerlink" title="9.5.1 Polynomials"></a>9.5.1 Polynomials</h2><p>Attention: $S$ represent the current state, and ${s_1, s_2, s_3, \cdots}$ represent the feature vector for state $S$</p>
<h2 id="9-5-2-Fourier-Basis"><a href="#9-5-2-Fourier-Basis" class="headerlink" title="9.5.2 Fourier Basis"></a>9.5.2 Fourier Basis</h2><h2 id="9-5-3-Coarse-Coding"><a href="#9-5-3-Coarse-Coding" class="headerlink" title="9.5.3 Coarse Coding"></a>9.5.3 Coarse Coding</h2><p>Features with large receptive fields give broad generalization, but might also seem to limit the learned function to a coarse approximation, unable to make discriminations much finer than the width of the receptive fields. Happily, this is not the case. Initial generalization from one point to another is indeed controlled by the size and shape of the receptive fields, but acuity, the finest discrimination ultimately possible, is controlled more by the total number of features.</p>
<p>So it’s foundmentally like the feature function. We input a complex, high level space into the function, and the function will output a low level, simple space. corase coding is using several smaller pieces circle to cover all feature spaces. So why not use convolutional neural network to do this? We can use convolution to gather feature space.</p>
<p>The receptive field of each feature is quite large. This means we can approximate the rough shape of the function with relatively few samples. As we sample the function more, our estimate forms a better and better approximation of the true function. The broad generalization of the longer intervals made learning faster. </p>
<h2 id="9-5-4-Tile-Coding"><a href="#9-5-4-Tile-Coding" class="headerlink" title="9.5.4 Tile Coding"></a>9.5.4 Tile Coding</h2><p>Is it like a CNN to encoding state space? Or Four active tiles/features overlap the point and are used to represent it. Does it mean that it’s not a CNN instead we use fource tile to code the feature space? </p>
<p>I am still confused about this whole chapter. It’s a chapter to build the feature for linear methods. So it’s some way to represent the feature. </p>
<h3 id="Using-Tile-Coding-in-TD"><a href="#Using-Tile-Coding-in-TD" class="headerlink" title="Using Tile Coding in TD"></a>Using Tile Coding in TD</h3><p>So tile coding is just used to simply encoding the feature space. tile coding has the overlap between the feature space for two different tiles. But state aggregation only has one feature space for one tile. So, tile coding is more complex than state aggregation.</p>
<p>Recall that when we created the tile coder we had to set several parameters, the size and shape of the tiles and the number of tilings. These parameters were fixed before learning. In a neural network, we have similar parameters corresponding to the number of layers, the number of nodes in each layer, and the activation functions. These are all, typically, fixed before learning.</p>
<p>One simple yet effective initialization strategy, is to randomly sample the initial weights from a normal distribution with small variance.</p>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>If recent gradients have all been in similar directions, then we gained momentum in that direction. This means, we make a large step in that direction. If recent updates have conflicting directions, then it kills the momentum. The momentum term will have little impact on the update and we will make a regular gradient descent step.</p>
<p>So we make a new term called momentum, we accumulate past historical gradient. And when the gradient is positive and negative, the momentum will be killed. </p>
<h4 id="Adam-Algorithm"><a href="#Adam-Algorithm" class="headerlink" title="Adam Algorithm"></a>Adam Algorithm</h4><p>In this assignment, instead of using SGD for updating the weights, we use a more advanced algorithm called Adam. The Adam algorithm improves the SGD update with two concepts: adaptive vector step-sizes and momentum. It keeps estimates of the mean and second moment of the updates, denoted by $\mathbf{m}$ and $\mathbf{v}$ respectively:<br>$$\mathbf{m_t} = \beta_m \mathbf{m_{t-1}} + (1 - \beta_m)g_t \<br>\mathbf{v_t} = \beta_v \mathbf{v_{t-1}} + (1 - \beta_v)g^2_t<br>$$</p>
<p>Given that $\mathbf{m}$ and $\mathbf{v}$ are initialized to zero, they are biased toward zero. To get unbiased estimates of the mean and second moment, Adam defines $\mathbf{\hat{m}}$ and $\mathbf{\hat{v}}$ as:<br>$$ \mathbf{\hat{m_t}} = \frac{\mathbf{m_t}}{1 - \beta_m^t} \<br>\mathbf{\hat{v_t}} = \frac{\mathbf{v_t}}{1 - \beta_v^t}<br>$$</p>
<p>we can see $\mathbf{m_t}$ has replace gradient, it’s the accumulated gradients and each time we add a $\beta$ ration of odd one and $1-\beta$ of the new one. And $v_t$ is the coefficient to control the momentum.<br>The weights are then updated as follows:<br>$$ \mathbf{w_t} = \mathbf{w_{t-1}} + \frac{\alpha}{\sqrt{\mathbf{\hat{v_t}}}+\epsilon} \mathbf{\hat{m_t}}<br>$$</p>
<p>When implementing the agent you will use the Adam algorithm instead of SGD because it is more efficient. We have already provided you the implementation of the Adam algorithm in the cell below. You will use it when implementing your agent. </p>
<h3 id="Vector-Step-Size"><a href="#Vector-Step-Size" class="headerlink" title="Vector Step Size"></a>Vector Step Size</h3><p>Vector step size is a vector of step parameter. each weight have their own step size.</p>
<p>Overall, On one hand, neural networks are powerful function approximators capable of representing a wide class of functions. They are also capable of producing features without exclusively relying on hand-crafted mechanisms. On the other hand, compared to a linear function approximator with tile-coding, neural networks can be less sample efficient. When implementing your own Reinforcement Learning agents, you may consider these strengths and weaknesses to choose the proper function approximator for your problems.</p>
<h2 id="9-5-5-Radial-Basis-Functions"><a href="#9-5-5-Radial-Basis-Functions" class="headerlink" title="9.5.5 Radial Basis Functions"></a>9.5.5 Radial Basis Functions</h2><p>Radial basis functions (RBFs) are the natural generalization of coarse coding to continuous- valued features. A typical RBF feature, $x_i$, has a Gaussian (bell-shaped) response $x_i(s)$ dependent only on the distance between the state, s, and the feature’s prototypical or center state, $c_i$, and relative to the feature’s width, $\sigma_i$: $x_i(s) = exp(-\frac{||s-c_i||^2}{2*\sigma_i^2})$</p>
<h2 id="9-6-Selecting-Step-Size-Parameters-Manually"><a href="#9-6-Selecting-Step-Size-Parameters-Manually" class="headerlink" title="9.6 Selecting Step-Size Parameters Manually"></a>9.6 Selecting Step-Size Parameters Manually</h2><p>A good rule of thumb for setting the step-size parameter of linear SGD methods is then<br>$(\tau<em>\mathbb{E}(X^{T}</em>X))^{-1}$<br>where x is a random feature vector chosen from the same distribution as input vectors will be in the SGD. This method works best if the feature vectors do not vary greatly in length; ideally $X^{T}*X$ is a constant.</p>
<h2 id="9-7-Nonlinear-Function-Approximation-Artificial-Neural-Networks"><a href="#9-7-Nonlinear-Function-Approximation-Artificial-Neural-Networks" class="headerlink" title="9.7 Nonlinear Function Approximation: Artificial Neural Networks"></a>9.7 Nonlinear Function Approximation: Artificial Neural Networks</h2><p>Training the hidden layers of an ANN is therefore a way to automatically create features appropriate for a given problem so that hierarchical representations can be produced without relying exclusively on hand-crafted features.</p>
<h2 id="9-8-Least-Squares-TD"><a href="#9-8-Least-Squares-TD" class="headerlink" title="9.8 Least-Squares TD"></a>9.8 Least-Squares TD</h2><p>Assume $A = x_t(x_t - \gamma x_{t+1})^T$ and $b = R_{t+1}x_t$. we can calculate the $w_{TD}$ as $A^{-1}b$</p>
<p>And we can also calculate the A at the time t directly. $A_t=\sum_{k=0}^{t-1}x_k(x_k - \gamma*x_{k+1})^T$</p>
<h2 id="9-9-Memory-based-Function-Approximation"><a href="#9-9-Memory-based-Function-Approximation" class="headerlink" title="9.9 Memory-based Function Approximation"></a>9.9 Memory-based Function Approximation</h2><p>They simply save training examples in memory as they arrive (or at least save a subset of the examples) without updating any parameters. Then, whenever a query state’s value estimate is needed, a set of examples is retrieved from memory and used to compute a value estimate for the query state. </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ReinforcementLearning/" rel="tag"># ReinforcementLearning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/27/%E6%9E%81%E8%B7%AF%E7%94%B1S1-%E6%97%A0%E5%AE%98%E6%96%B9%E7%A0%B4%E8%A7%A3%E8%B7%AF%E5%BE%84%E4%B8%8B%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B%EF%BC%8C%E8%BE%9B%E9%85%B8%E5%88%B7%E6%9C%BA%E5%8E%86%E7%A8%8B/" rel="prev" title="极路由S1-无官方破解路径下保姆级教程，辛酸刷机历程">
      <i class="fa fa-chevron-left"></i> 极路由S1-无官方破解路径下保姆级教程，辛酸刷机历程
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/29/ComputerArchitecture-Day1/" rel="next" title="ComputerArchitecture-Day1">
      ComputerArchitecture-Day1 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Preface"><span class="nav-number">1.</span> <span class="nav-text">Preface</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-1-Value-function-Approximation"><span class="nav-number">1.2.</span> <span class="nav-text">9.1 Value-function Approximation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-2-The-Prediction-Objective-VE"><span class="nav-number">1.3.</span> <span class="nav-text">9.2 The Prediction Objective (VE)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-3-Stochastic-gradient-and-Semi-gradient-Methods"><span class="nav-number">1.4.</span> <span class="nav-text">9.3 Stochastic-gradient and Semi-gradient Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-4-Linear-Methods"><span class="nav-number">1.5.</span> <span class="nav-text">9.4 Linear Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-Feature-Construction-for-Linear-Methods"><span class="nav-number">1.6.</span> <span class="nav-text">9.5 Feature Construction for Linear Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-1-Polynomials"><span class="nav-number">1.7.</span> <span class="nav-text">9.5.1 Polynomials</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-2-Fourier-Basis"><span class="nav-number">1.8.</span> <span class="nav-text">9.5.2 Fourier Basis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-3-Coarse-Coding"><span class="nav-number">1.9.</span> <span class="nav-text">9.5.3 Coarse Coding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-4-Tile-Coding"><span class="nav-number">1.10.</span> <span class="nav-text">9.5.4 Tile Coding</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-Tile-Coding-in-TD"><span class="nav-number">1.10.1.</span> <span class="nav-text">Using Tile Coding in TD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Momentum"><span class="nav-number">1.10.2.</span> <span class="nav-text">Momentum</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Adam-Algorithm"><span class="nav-number">1.10.2.1.</span> <span class="nav-text">Adam Algorithm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vector-Step-Size"><span class="nav-number">1.10.3.</span> <span class="nav-text">Vector Step Size</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-5-5-Radial-Basis-Functions"><span class="nav-number">1.11.</span> <span class="nav-text">9.5.5 Radial Basis Functions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-6-Selecting-Step-Size-Parameters-Manually"><span class="nav-number">1.12.</span> <span class="nav-text">9.6 Selecting Step-Size Parameters Manually</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-7-Nonlinear-Function-Approximation-Artificial-Neural-Networks"><span class="nav-number">1.13.</span> <span class="nav-text">9.7 Nonlinear Function Approximation: Artificial Neural Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-8-Least-Squares-TD"><span class="nav-number">1.14.</span> <span class="nav-text">9.8 Least-Squares TD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-9-Memory-based-Function-Approximation"><span class="nav-number">1.15.</span> <span class="nav-text">9.9 Memory-based Function Approximation</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhongzhu / Chralie Zhou"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhongzhu / Chralie Zhou</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zzz0906" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zzz0906" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhongzhu.zhou@sydney.edu.au" title="E-Mail → mailto:zhongzhu.zhou@sydney.edu.au" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com.hk/citations?user=BoZKZl4AAAAJ&hl=zh-CN" title="Scholar → https:&#x2F;&#x2F;scholar.google.com.hk&#x2F;citations?user&#x3D;BoZKZl4AAAAJ&amp;hl&#x3D;zh-CN" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Scholar</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/zhongzhu-zhou/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhongzhu-zhou&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin-in fa-fw"></i>Linkedin</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhongzhu / Chralie Zhou</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
